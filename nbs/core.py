# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/00core.ipynb.

# %% auto 0
__all__ = ['folder', 'host', 'mapbox_access_token', 'SCMGraph', 'co2', 'time_delta', 'add_seconds', 'compute_durations',
           'make_time_df', 'make_durations']

# %% ../nbs/00core.ipynb 2
from typing import List, Optional, Union, Tuple, Dict, Set, Any, DefaultDict
from pydantic import BaseModel, Field, ValidationError, validator, confloat, conint, constr, Json
from pydantic.tools import parse_obj_as
from datetime import datetime, date, time

import random
import datetime as dt
import networkx as nx
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import plotly
import plotly.graph_objs as go
from collections import defaultdict, OrderedDict, Counter
import requests
import math

folder = "./data/"
host = "test-osrm-intel.aq-cloud.com"
mapbox_access_token = 'pk.eyJ1IjoibWlraW9rdWJvIiwiYSI6ImNqYXQ3dHBqdzR5ZGwyd3BkeG5rOTl0b2UifQ.1utsXNi2V-WdzfWlvCMj_A'

# %% ../nbs/00core.ipynb 4
class SCMGraph(nx.DiGraph):
    '''
     SCMGraph is a class of directed graph with edge weight that can be any object.
     I just use the functions such as in_degree, out_degree, successors,
     predecessors, in_edges_iter, out_edges_iter.
     So it is convertible to any graph class that can access the adjacent nodes more quickly.
    '''

    def random_directed_tree(self, n=1, seed=None):
        """
        generate random directed tree
        """
        random.seed(seed)
        G = nx.generators.trees.random_tree(n=n, seed=seed)
        #print("seed=",seed)
        self.add_nodes_from(G)
        for (u, v) in G.edges():
            if random.random() <= 0.5:
                self.add_edge(u, v)
            else:
                self.add_edge(v, u)

    def layered_network(self, num_in_layer=None, p=0.5, seed=None):
        '''
          Input the number of nodes in layers as a list like NumInLayer=[4,5,6,7]
          and the probability with which edge occures,
          return a layered and connected directed graph
        '''

        random.seed(seed)
        if num_in_layer is None:
            num_in_layer = [1, 1]
        else:
            num_in_layer = list(num_in_layer)
        Layer = []
        startID = 0
        layerID = {}
        numlayer = 0
        for l in num_in_layer:
            endID = startID+l
            Layer.append((range(startID, endID)))  # append to the layer
            for i in range(startID, endID):
                layerID[i] = numlayer  # store the layer index of the node
            numlayer += 1
            startID = endID
        n = endID
        self.add_nodes_from(range(n))
        for l in range(len(Layer)-1):
            for i in Layer[l]:
                for j in Layer[l+1]:
                    if random.random() <= p:  # add an edge w.p. "p"
                        self.add_edge(i, j)

    def layout(self):
        '''
        Compute x,y coordinates for the supply chain
           The algorithm is based on a simplified version of Sugiyama's method.
           First assign each node to the (minimum number of) layers;
           Then compute the y coordinate by computing the means of y-values
           of adjacent nodes
           return the dictionary of (x,y) positions of the nodes
        '''
        longest_path = nx.dag_longest_path(self)
        LayerLB = {}
        pos = {}
        MaxLayer = len(longest_path)
        candidate = set([i for i in self]) - set(longest_path)
        #print(longest_path)
        for i in candidate:
            LayerLB[i] = 0

        Layer = defaultdict(list)
        for i, v in enumerate(longest_path):
            Layer[i] = [v]
            LayerLB[v] = i
            for w in self.successors(v):
                if w in candidate:
                    LayerLB[w] = LayerLB[v]+1

        L = list(nx.topological_sort(self))

        for v in L:
            if v in candidate:
                #print(v,end=" ")
                Layer[LayerLB[v]].append(v)
                candidate.remove(v)
                for w in self.successors(v):
                    if w in candidate:
                        LayerLB[w] = max(LayerLB[v]+1, LayerLB[w])

        MaxLayer = len(Layer)
        for i in range(MaxLayer+1):
            if i == 0:
                j = 0
                for v in Layer[i]:
                    pos[v] = (i, j)
                    j += 1
            else:
                tmplist = []
                for v in Layer[i]:
                    sumy = 0.0
                    j = 0.0
                    for w in self.predecessors(v):
                        (ii, jj) = pos[w]
                        sumy += jj
                        j += 1.0
                    if j != 0:
                        temp = sumy/j
                    else:
                        temp = j
                    tmplist.append((temp, v))
                tmplist.sort()
                order = [v for (_, v) in tmplist]
                j = 0
                for v in Layer[i]:
                    pos[order[j]] = (i, j)
                    j += 1
        return pos

    def down_order(self):
        '''
        generator fuction in topological order
        generate the order of nodes from suppliers to demand points
        '''
        degree0 = []
        degree = {}
        for v in self:
            if self.in_degree(v) == 0:
                degree0.append(v)
            else:
                degree[v] = self.in_degree(v)
        # print degree0
        while degree0:
            v = degree0.pop()
            # print v
            yield v
            for w in self.successors(v):
                degree[w] -= 1
                if degree[w] == 0:
                    degree0.append(w)

    def up_order(self):
        '''
        Generator fuction in the reverse topological order
        generate the order of nodes from to demand points to suppliers
        '''
        degree0 = []
        degree = {}
        for v in self:
            if self.out_degree(v) == 0:
                degree0.append(v)
            else:
                degree[v] = self.out_degree(v)
        while degree0:
            v = degree0.pop()
            yield v
           # print v
            for w in self.predecessors(v):
                degree[w] -= 1
                if degree[w] == 0:
                    degree0.append(w)

    def dp_order(self):
        '''
        Generater function for the safety stock allocation problem
        This function returns (yields) the leaf ordering sequence of nodes
        Remark: the graph must be tree! Otherwise, this function does not generate
        all the nodes.
        '''

        # check the underling graph is a tree or not
        is_tree = nx.is_tree(self)
        if is_tree == False:
            print("Graph is not a tree.")
            return

        Leaf = set([])
        Searched = set([])
        degree = {}
        for v in self:
            degree[v] = self.out_degree(v)+self.in_degree(v)
            if degree[v] <= 1:
                Leaf.add(v)

        while Leaf:
            v = Leaf.pop()
            # print v,Leaf
            yield v
            Searched.add(v)
            for w in set(self.successors(v)) | set(self.predecessors(v)):
                # print "adj=",w
                if w not in Searched:
                    if degree[w] >= 2:
                        degree[w] -= 1
                    if degree[w] <= 1:
                        Leaf.add(w)

    def bfs(self, start=None):
        '''
        breadth first search from a given node 'start'
        '''
        if start is None:
            start = list(self.nodes)[0]
        L = []
        L.append(start)  # L is the list that keeps the active (front) nodes
        # Searched is the set that includes all the nodes searched so far
        Searched = set([start])
        while L:
            v = L.pop(0)  # extract the first element in the list
            # print v," is searched"
            yield v
            for w in self.successors(v):
                if w not in Searched:
                    L.append(w)
                    Searched.add(w)
                    # print "L=",L,Searched
                else:
                    print(f"arc ({v}, {w}) makes a cycle")

    def find_ancestors(self):
        '''
        find the ancestors based on the BOM graph
        The set of ancestors of node i is the set of nodes that are reachable from node i (including i).
        '''
        ancestors = {v:set([]) for v in self}
        for v in self.up_order():
            ancestors[v] = ancestors[v] | set([v])
            for w in self.successors(v):
                ancestors[v] = ancestors[v] | ancestors[w]
        return ancestors

# %% ../nbs/00core.ipynb 7
def co2(capacity, rate = 0.5, diesel=False):
    """
    引数： 
       - capacity：積載重量（kg)
       - rate: 積載率 (0<rate<=1.0)
       - diesel: ディーゼル車の場合 True， ガソリン車の場合 False
    返値：
       - fuel: トンキロあたりの燃料使用量（リットル）
       - co2: CO2排出量(g)
    """
    if diesel:
        fuel = math.e**(2.67-0.927*math.log(rate) - 0.648*math.log(capacity))
    else:
        fuel = math.e**(2.71-0.812*math.log(rate) - 0.654*math.log(capacity))
    co2 = fuel*2.322*1000
    return fuel, co2

# %% ../nbs/00core.ipynb 9
def time_delta(finish, start):
    """
    日付時刻もしくは時刻型の差を計算して，秒を返す関数
    """
    try: #datetime型
        return int((finish-start).total_seconds())
    except TypeError: #time型
        td = (dt.datetime.combine(dt.date(2000,1,1), finish) - dt.datetime.combine(dt.date(2000,1,1), start) )
        return td.days*60*60*24 + td.seconds
        #return (dt.datetime.combine(dt.date(2000,1,1), finish) - dt.datetime.combine(dt.date(2000,1,1), start) ).seconds

# %% ../nbs/00core.ipynb 13
def add_seconds(start, seconds):
    try:
        finish = start + dt.timedelta(seconds=seconds)
        return finish.strftime("%Y-%m-%d %H:%M")
    except TypeError:
        finish = (dt.datetime.combine(dt.date(2000,1,1), start) + dt.timedelta(seconds=seconds))
        return finish.strftime("%H:%M")

# %% ../nbs/00core.ipynb 17
def compute_durations(cust_df, plnt_df=None, toll=True, host="localhost"):
    
    if plnt_df is not None:
        node_df = pd.concat( [cust_df[["name","lat","lon"]], plnt_df[["name","lat","lon"] ] ] )
    else:
        node_df = cust_df.copy()
    n=len(node_df)
    ROUTE =[]
    for row in node_df.itertuples():
        ROUTE.append( [row.lat, row.lon] )
    route_str =""
    for (i,j) in ROUTE[:]:
        route_str += str(j)+","+str(i)+";"
    #print(f"http://{host}:5000/table/v1/driving/'"+route_str[:-1]+"?annotations=distance,duration")
    #response = requests.get('http://localhost:5000/table/v1/driving/'+route_str[:-1]+"?annotations=distance,duration&exclude=motorway")
    if toll:
        response = requests.get(f'http://{host}:5000/table/v1/driving/'+route_str[:-1]+"?annotations=distance,duration")
    else:
        response = requests.get(f'http://{host}:5000/table/v1/driving/'+route_str[:-1]+"?annotations=distance,duration&exclude=toll")
    result = response.json()

    try:
        durations = result["durations"]
        distances = result["distances"]
    except:
        raise ValueError 
    for i in range(n):
        for j in range(n):
            if durations[i][j] is None:
                #print(i,j)
                durations[i][j] = 3600*24
                distances[i][j] = 1000000
    return  durations, distances, node_df

# %% ../nbs/00core.ipynb 21
def make_time_df(node_df, durations, distances):
    try:
        node_df.reset_index(inplace=True)
    except:
        pass
    
    n = len(durations)
    name_dic = node_df.name.to_dict() #番号を顧客名に写像
    from_id, to_id, duration, distance =[],[],[],[]
    from_name, to_name = [], [] 
    for i in range(n):
        for j in range(n):
            from_id.append(i)
            to_id.append(j)
            from_name.append(name_dic[i])
            to_name.append(name_dic[j])
            duration.append( int(durations[i][j]) )
            distance.append( int(distances[i][j]) )
    time_df = pd.DataFrame({"from_node": from_id, "from_name": from_name, "to_node":to_id, "to_name":to_name, "time": duration, "distance": distance })
    return time_df

# %% ../nbs/00core.ipynb 25
def make_durations(time_df):
    n = time_df.from_node.max() + 1
    durations = np.zeros((n,n))
    distances = np.zeros((n,n))
    for row in time_df.itertuples():
        durations[ int(row.from_node), int(row.to_node) ] = int(row.time)
        distances[ int(row.from_node), int(row.to_node) ] = int(row.distance)
    return durations, distances
